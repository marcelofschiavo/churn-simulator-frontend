import gradio as gr
import requests
import json
import os
import google.generativeai as genai # <-- Mantenha o import

# 1. URL da sua API FastAPI (o Backend)
API_URL = "https://marcelofschiavo-churn-api-v1.hf.space/predict" 

# üö´ REMOVA a configura√ß√£o global do Gemini daqui.
# Vamos configurar o modelo DENTRO da fun√ß√£o.

def get_churn_prediction_and_advice(salario, tempo_dias, dias_login, media_logado, chamados, departamento):
    """
    Fun√ß√£o principal: Chama a API (N√≠vel 3) e depois o LLM (N√≠vel 5).
    """
    
    # --- ETAPA 1: CHAMAR A API FASTAPI ---
    payload = {
        "salario_mensal": salario, "tempo_empresa_dias": tempo_dias,
        "dias_desde_ultimo_login": dias_login, "media_tempo_logado_min": media_logado,
        "total_chamados_suporte": chamados, "departamento": departamento
    }
    
    try:
        response = requests.post(API_URL, json=payload, timeout=10)
        response.raise_for_status() 
        resultado_api = response.json()
        probabilidade = resultado_api.get("probabilidade_de_churn", 0.0)
        status = "ALTO RISCO" if probabilidade > 0.5 else "BAIXO RISCO"
        resultado_previsao = f"PREVIS√ÉO DO MODELO: {status} ({probabilidade:.2%})"
        
    except requests.exceptions.RequestException as e:
        return f"ERRO CR√çTICO: A API FastAPI (Backend) n√£o respondeu. Detalhes: {e}"

    # --- ETAPA 2: CHAMAR O LLM (N√çVEL 5) ---
    # ‚≠ê‚≠ê‚≠ê CORRE√á√ÉO: Lemos a chave e configuramos o modelo AQUI DENTRO ‚≠ê‚≠ê‚≠ê
    
    recomendacoes_llm = ""
    GEMINI_KEY = os.environ.get("GEMINI_API_KEY") # L√™ o Secret do HFS AQUI

    if GEMINI_KEY and probabilidade > 0.3: # S√≥ gera se a chave existir E o risco for relevante
        try:
            genai.configure(api_key=GEMINI_KEY)
            model = genai.GenerativeModel('gemini-1.5-flash')
            
            prompt = f"""
            Voc√™ √© um Consultor S√™nior de People Analytics.
            A probabilidade de churn para o funcion√°rio do departamento '{departamento}' 
            com sal√°rio R${salario} e {dias_login} dias sem logar √© de {probabilidade:.2%}.
            
            Gere 3 (tr√™s) recomenda√ß√µes ACION√ÅVEIS e DIRETAS para o RH mitigar este risco.
            Seja breve e profissional.
            """
            
            response_llm = model.generate_content(prompt)
            recomendacoes_llm = response_llm.text
            
        except Exception as e:
            recomendacoes_llm = f"ERRO ao gerar IA: {e}"
    else:
        recomendacoes_llm = "Recomenda√ß√µes da IA desabilitadas (Chave n√£o configurada ou Risco Baixo)."

    # --- ETAPA 3: RETORNO FINAL ---
    return (
        f"{resultado_previsao}\n\n"
        f"--- RECOMENDA√á√ïES DE INTERVEN√á√ÉO (IA) ---\n"
        f"{recomendacoes_llm}"
    )

# --- Configura√ß√£o da Interface Gradio ---
# (O restante do c√≥digo gr.Interface permanece o MESMO)
inputs = [
    gr.Number(label="Sal√°rio Mensal (R$)", value=5000),
    gr.Number(label="Tempo de Empresa (dias)", value=700),
    gr.Number(label="Dias desde √öltimo Login", value=10),
    gr.Number(label="M√©dia de Tempo Logado (min)", value=60),
    gr.Number(label="Total de Chamados Suporte", value=2),
    gr.Dropdown(label="Departamento", choices=['TI', 'Vendas', 'RH', 'Marketing'], value='Vendas')
]

gr.Interface(
    fn=get_churn_prediction_and_advice,
    inputs=inputs,
    outputs=gr.Textbox(label="An√°lise Preditiva e Prescritiva", lines=10),
    title="Simulador de Risco de Churn (N√≠vel 5)",
    description="Interface Gradio (Frontend) que consome a API FastAPI (Backend) e gera recomenda√ß√µes com IA (Gemini)."
).launch()